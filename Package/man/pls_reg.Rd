% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pls_reg.R
\name{pls_reg}
\alias{pls_reg}
\title{Partial least squares "regression decomposition" (PLSREG)}
\usage{
pls_reg(
  X,
  Y,
  center_X = TRUE,
  center_Y = TRUE,
  scale_X = TRUE,
  scale_Y = TRUE,
  components = 0,
  tol = .Machine$double.eps
)
}
\arguments{
\item{X}{Data matrix with \emph{I} rows and \emph{J} columns}

\item{Y}{Data matrix with \emph{I} rows and \emph{K} columns}

\item{center_X}{For the \code{X} matrix: A parameter to pass through to \code{center} in \code{\link{scale}} function; either a logical value or numeric-alike vector of length equal to the number of columns of \code{X}.}

\item{center_Y}{For the \code{Y} matrix: A parameter to pass through to \code{center} in \code{\link{scale}} function; either a logical value or numeric-alike vector of length equal to the number of columns of \code{Y}.}

\item{scale_X}{For the \code{X} matrix: A parameter to pass through to \code{scale} in \code{\link{scale}} function; either a logical value or numeric-alike vector of length equal to the number of columns of \code{X}.}

\item{scale_Y}{For the \code{Y} matrix: A parameter to pass through to \code{scale} in \code{\link{scale}} function; either a logical value or numeric-alike vector of length equal to the number of columns of \code{Y}.}

\item{components}{The number of components to return. If < 1 then the maximum components will be returned. Default = 0.}

\item{tol}{default is .Machine$double.eps. A parameter to pass through to \code{\link[GSVD]{gplssvd}}; eliminates singular values that are effectively zero (and thus drops null components).}
}
\value{
A list of outputs based on \code{\link{gpls_reg}}
\item{d}{A vector containing the singular values from each iteration.}
\item{u}{Left (rows) singular vectors.}
\item{v}{Right (columns) singular vectors. In PLSREG sometimes called "weight matrix".}
\item{lx}{Latent variable scores for rows of \code{X}}
\item{ly}{Latent variable scores for rows of \code{Y}}
\item{p}{Left (rows) generalized singular vectors.}
\item{q}{Right (columns) generalized singular vectors.}
\item{fi}{Left (rows) component scores.}
\item{fj}{Right (columns) component scores.}
\item{tx}{"Latent vectors": A normed version of \code{lx} for use in rebuilding \code{X} data}
\item{u_hat}{"Loading matrix": A "predicted" version of \code{u} for use in rebuilding \code{X} data}
\item{betas}{"Regression weights": Akin to betas for use in rebuilding \code{Y}}
\item{X_reconstructeds}{A version of \code{X} reconstructed for each iteration (i.e., latent variable/component)}
\item{Y_reconstructeds}{A version of \code{Y} reconstructed for each iteration (i.e., latent variable/component)}
\item{X_residuals}{The residualized (i.e., \code{X - X_reconstructeds}) version of \code{X} for each iteration (i.e., latent variable/component)}
\item{Y_residuals}{The residualized (i.e., \code{Y - Y_reconstructeds}) version of \code{Y} for each iteration (i.e., latent variable/component)}
\item{r2_x}{Proportion of explained variance from \code{X} to each latent variable/component.}
\item{r2_y}{Proportion of explained variance from \code{Y} to each latent variable/component.}
\item{Y_reconstructed}{A version of \code{Y} reconstructed from all iterations (i.e., latent variables/components); see \code{components}.}
\item{Y_residual}{The residualized (i.e., \code{Y - Y_reconstructed} from all iterations (i.e., latent variables/components); see \code{components}.}
\item{Y_reconstructed_hat}{The re-centered and re-scaled version of \code{Y_reconstructed} to have the same center and scale as \code{Y}.}
\item{Y_residual_hat}{The re-centered and re-scaled version of \code{Y_residual} to have the same center and scale as \code{Y}.}
}
\description{
Computes partial least squares "regression decomposition" between two data matrices by way of generalized PLS regression decomposition
}
\examples{
 data("wine", package = "GSVD")
 plsreg_results <- pls_reg(wine$objective, wine$subjective)

 \dontrun{
     ## Like PLSCOR, PLSREG maximizes the latent variables:
     diag( t(plsreg_results$lx) \%*\% plsreg_results$ly ) ## same as plsreg_results$d
     plsreg_results$d

     ## but this is an asymmetric relationship:
     crossprod(plsreg_results$lx) #orthogonal
     t(plsreg_results$lx) \%*\% plsreg_results$ly ## a triangular matrix
 }

}
\references{
Abdi, H. (2010). Partial least square regression, projection on latent structure regression, PLS-Regression. \emph{Wiley Interdisciplinary Reviews: Computational Statistics}, \bold{2}, 97-106.
Geladi, P., & Kowalski, B. R. (1986). Partial least-squares regression: a tutorial. \emph{Analytica chimica acta}, 185, 1-17.
Tenenhaus, M. (1998). La Regression PLS. Theorie et Pratique. \emph{Editions TECHNIP}, Paris.
Wold, S., Ruhe, A., Wold, H., & Dunn, III, W. J. (1984). The collinearity problem in linear regression. The partial least squares (PLS) approach to generalized inverses. \emph{SIAM Journal on Scientific and Statistical Computing}, 5(3), 735-743.
}
\seealso{
\code{\link{plsca_reg}} \code{\link{pls_cor}} \code{\link{gpls_reg}} \code{\link[GSVD]{gplssvd}},
}
\keyword{diagonalization,}
\keyword{least}
\keyword{multivariate,}
\keyword{partial}
\keyword{squares}
